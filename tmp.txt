float aclFloat16ToFloat(aclFloat16 value);
aclFloat16 aclFloatToFloat16(float value);
aclDataBuffer *aclCreateDataBuffer(void *data, size_t size);
aclError aclDestroyDataBuffer(const aclDataBuffer *dataBuffer);
aclError aclUpdateDataBuffer(aclDataBuffer *dataBuffer, void *data, size_t size);
void *aclGetDataBufferAddr(const aclDataBuffer *dataBuffer);
uint32_t aclGetDataBufferSize(const aclDataBuffer *dataBuffer);
size_t aclGetDataBufferSizeV2(const aclDataBuffer *dataBuffer);
size_t aclDataTypeSize(aclDataType dataType);
aclTensorDesc *aclCreateTensorDesc(aclDataType dataType, int numDims, const int64_t *dims, aclFormat format);
void aclDestroyTensorDesc(const aclTensorDesc *desc);
aclError aclSetTensorShapeRange(aclTensorDesc* desc, size_t dimsCount, int64_t dimsRange[][2]);
aclError aclSetTensorValueRange(aclTensorDesc* desc, size_t valueCount, int64_t valueRange[][2]);
aclDataType aclGetTensorDescType(const aclTensorDesc *desc);
aclFormat aclGetTensorDescFormat(const aclTensorDesc *desc);
size_t aclGetTensorDescSize(const aclTensorDesc *desc);
size_t aclGetTensorDescElementCount(const aclTensorDesc *desc);
size_t aclGetTensorDescNumDims(const aclTensorDesc *desc);
int64_t aclGetTensorDescDim(const aclTensorDesc *desc, size_t index);
aclError aclGetTensorDescDimV2(const aclTensorDesc *desc, size_t index, int64_t *dimSize);
aclError aclGetTensorDescDimRange(const aclTensorDesc *desc, size_t index, size_t dimRangeNum, int64_t *dimRange);
void aclSetTensorDescName(aclTensorDesc *desc, const char *name);
const char *aclGetTensorDescName(aclTensorDesc *desc);
aclError aclTransTensorDescFormat(const aclTensorDesc *srcDesc, aclFormat dstFormat, aclTensorDesc **dstDesc);
aclError aclSetTensorStorageFormat(aclTensorDesc *desc, aclFormat format);
aclError aclSetTensorStorageShape(aclTensorDesc *desc, int numDims, const int64_t *dims);
aclError aclSetTensorFormat(aclTensorDesc *desc, aclFormat format);
aclError aclSetTensorShape(aclTensorDesc *desc, int numDims, const int64_t *dims);
aclError aclSetTensorOriginFormat(aclTensorDesc *desc, aclFormat format);
aclError aclSetTensorOriginShape(aclTensorDesc *desc, int numDims, const int64_t *dims);
aclTensorDesc *aclGetTensorDescByIndex(aclTensorDesc *desc, size_t index);
void *aclGetTensorDescAddress(const aclTensorDesc *desc);
aclError aclSetTensorDynamicInput(aclTensorDesc *desc, const char *dynamicInputName);
aclError aclSetTensorConst(aclTensorDesc *desc, void *dataBuffer, size_t length);
aclError aclSetTensorPlaceMent(aclTensorDesc *desc, aclMemType memType);
void aclAppLog(aclLogLevel logLevel, const char *func, const char *file, uint32_t line, const char *fmt, ...);
const char *aclrtGetSocName();
aclError aclGetCannAttributeList(const aclCannAttr **cannAttrList, size_t *num);
aclError aclGetCannAttribute(aclCannAttr cannAttr, int32_t *value);
aclError aclGetDeviceCapability(uint32_t deviceId, aclDeviceInfo deviceInfo, int64_t *value);
aclTensor *aclCreateTensor(const int64_t *viewDims, uint64_t viewDimsNum, aclDataType dataType, const int64_t *stride, int64_t offset, aclFormat format, const int64_t *storageDims, uint64_t storageDimsNum, void *tensorData);
aclScalar *aclCreateScalar(void *value, aclDataType dataType);
aclIntArray *aclCreateIntArray(const int64_t *value, uint64_t size);
aclFloatArray *aclCreateFloatArray(const float *value, uint64_t size);
aclBoolArray *aclCreateBoolArray(const bool *value, uint64_t size);
aclTensorList *aclCreateTensorList(const aclTensor *const *value, uint64_t size);
aclScalarList *aclCreateScalarList(const aclScalar *const *value, uint64_t size);
aclnnStatus aclDestroyTensor(const aclTensor *tensor);
aclnnStatus aclDestroyScalar(const aclScalar *scalar);
aclnnStatus aclDestroyIntArray(const aclIntArray *array);
aclnnStatus aclDestroyFloatArray(const aclFloatArray *array);
aclnnStatus aclDestroyBoolArray(const aclBoolArray *array);
aclnnStatus aclDestroyTensorList(const aclTensorList *array);
aclnnStatus aclDestroyScalarList(const aclScalarList *array);
aclnnStatus aclGetViewShape(const aclTensor *tensor, int64_t **viewDims, uint64_t *viewDimsNum);
aclnnStatus aclGetStorageShape(const aclTensor *tensor, int64_t **storageDims, uint64_t *storageDimsNum);
aclnnStatus aclGetViewStrides(const aclTensor *tensor, int64_t **stridesValue, uint64_t *stridesNum);
aclnnStatus aclGetViewOffset(const aclTensor *tensor, int64_t *offset);
aclnnStatus aclGetFormat(const aclTensor *tensor, aclFormat *format);
aclnnStatus aclGetDataType(const aclTensor *tensor, aclDataType *dataType);
aclnnStatus aclGetIntArraySize(const aclIntArray *array, uint64_t *size);
aclnnStatus aclGetFloatArraySize(const aclFloatArray *array, uint64_t *size);
aclnnStatus aclGetBoolArraySize(const aclBoolArray *array, uint64_t *size);
aclnnStatus aclGetTensorListSize(const aclTensorList *tensorList, uint64_t *size);
aclnnStatus aclGetScalarListSize(const aclScalarList *scalarList, uint64_t *size);
aclnnStatus aclInitTensor(aclTensor *tensor, const int64_t *viewDims, uint64_t viewDimsNum, aclDataType dataType, const int64_t *stride, int64_t offset, aclFormat format, const int64_t *storageDims, uint64_t storageDimsNum, void *tensorDataAddr);
aclnnStatus aclSetAclOpExecutorRepeatable(aclOpExecutor *executor);
aclnnStatus aclDestroyAclOpExecutor(aclOpExecutor *executor);
aclnnStatus AclSetInputTensorAddr(aclOpExecutor *executor, const size_t index, aclTensor *tensor, void *addr);
aclnnStatus AclSetOutputTensorAddr(aclOpExecutor *executor, const size_t index, aclTensor *tensor, void *addr);
aclnnStatus AclSetDynamicInputTensorAddr(aclOpExecutor *executor, size_t irIndex, const size_t relativeIndex, aclTensorList *tensors, void *addr);
aclnnStatus AclSetDynamicOutputTensorAddr(aclOpExecutor *executor, size_t irIndex, const size_t relativeIndex, aclTensorList *tensors, void *addr);
aclnnStatus AclSetTensorAddr(aclOpExecutor *executor, const size_t index, aclTensor *tensor, void *addr);
aclnnStatus AclSetDynamicTensorAddr(aclOpExecutor *executor, size_t irIndex, const size_t relativeIndex, aclTensorList *tensors, void *addr);
aclnnStatus aclSetInputTensorAddr(aclOpExecutor *executor, const size_t index, aclTensor *tensor, void *addr);
aclnnStatus aclSetOutputTensorAddr(aclOpExecutor *executor, const size_t index, aclTensor *tensor, void *addr);
aclnnStatus aclSetDynamicInputTensorAddr(aclOpExecutor *executor, size_t irIndex, const size_t relativeIndex, aclTensorList *tensors, void *addr);
aclnnStatus aclSetDynamicOutputTensorAddr(aclOpExecutor *executor, size_t irIndex, const size_t relativeIndex, aclTensorList *tensors, void *addr);
aclnnStatus aclSetTensorAddr(aclOpExecutor *executor, const size_t index, aclTensor *tensor, void *addr);
aclnnStatus aclSetDynamicTensorAddr(aclOpExecutor *executor, size_t irIndex, const size_t relativeIndex, aclTensorList *tensors, void *addr);
aclnnStatus aclnnInit(const char *configPath);
aclnnStatus aclnnFinalize();
aclnnStatus aclnnAbsGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAbs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAcosGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAcos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceAcosGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAcos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAcoshGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAcosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAcoshGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAcosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAdaptiveAvgPool2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAdaptiveAvgPool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAdaptiveMaxPool2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, aclTensor* outputOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAdaptiveMaxPool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAddGetWorkspaceSize(const aclTensor* self, const aclTensor* other, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAddsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAdds(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAddGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other, const aclScalar* alpha, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAddsGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other, const aclScalar* alpha, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAdds(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAddbmmGetWorkspaceSize(const aclTensor* self, const aclTensor* batch1, const aclTensor* batch2, const aclScalar* beta, const aclScalar* alpha, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAddbmmGetWorkspaceSize(aclTensor* selfRef, const aclTensor* batch1, const aclTensor* batch2, const aclScalar* beta, const aclScalar* alpha, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAddcdivGetWorkspaceSize(const aclTensor* self, const aclTensor* tensor1, const aclTensor* tensor2, const aclScalar* value, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAddcdiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceAddcdivGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* tensor1, const aclTensor* tensor2, const aclScalar* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAddcdiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAddcmulGetWorkspaceSize(const aclTensor* self, const aclTensor* tensor1, const aclTensor* tensor2, const aclScalar* value, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAddcmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAddcmulGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* tensor1, const aclTensor* tensor2, const aclScalar* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAddcmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAddmmGetWorkspaceSize(const aclTensor* self, const aclTensor* mat1, const aclTensor* mat2, const aclScalar* beta, const aclScalar* alpha, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAddmmGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* mat1, const aclTensor* mat2, const aclScalar* beta, const aclScalar* alpha, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAddmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceAddmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAddmvGetWorkspaceSize(const aclTensor* self, const aclTensor* mat, const aclTensor* vec, const aclScalar* alpha, const aclScalar* beta, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAddmv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAddrGetWorkspaceSize(const aclTensor* self, const aclTensor* vec1, const aclTensor* vec2, const aclScalar* betaOptional, const aclScalar* alphaOptional, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAddr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceAddrGetWorkspaceSize(aclTensor* selfRef, const aclTensor* vec1, const aclTensor* vec2, const aclScalar* betaOptional, const aclScalar* alphaOptional, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAddr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAffineGridGetWorkspaceSize(const aclTensor* theta, const aclIntArray* size, bool alignCorners, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAffineGrid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAllGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAll(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclError aclrtSetExceptionInfoCallback(aclrtExceptionInfoCallback callback);
uint32_t aclrtGetTaskIdFromExceptionInfo(const aclrtExceptionInfo *info);
uint32_t aclrtGetStreamIdFromExceptionInfo(const aclrtExceptionInfo *info);
uint32_t aclrtGetThreadIdFromExceptionInfo(const aclrtExceptionInfo *info);
uint32_t aclrtGetDeviceIdFromExceptionInfo(const aclrtExceptionInfo *info);
uint32_t aclrtGetErrorCodeFromExceptionInfo(const aclrtExceptionInfo *info);
aclError aclrtSubscribeReport(uint64_t threadId, aclrtStream stream);
aclError aclrtLaunchCallback(aclrtCallback fn, void *userData, aclrtCallbackBlockType blockType, aclrtStream stream);
aclError aclrtProcessReport(int32_t timeout);
aclError aclrtUnSubscribeReport(uint64_t threadId, aclrtStream stream);
aclError aclrtCreateContext(aclrtContext *context, int32_t deviceId);
aclError aclrtDestroyContext(aclrtContext context);
aclError aclrtSetCurrentContext(aclrtContext context);
aclError aclrtGetCurrentContext(aclrtContext *context);
aclError aclrtCtxGetSysParamOpt(aclSysParamOpt opt, int64_t *value);
aclError aclrtCtxSetSysParamOpt(aclSysParamOpt opt, int64_t value);
aclError aclrtSetDevice(int32_t deviceId);
aclError aclrtResetDevice(int32_t deviceId);
aclError aclrtGetDevice(int32_t *deviceId);
aclError aclrtSetStreamFailureMode(aclrtStream stream, uint64_t mode);
aclError aclrtGetRunMode(aclrtRunMode *runMode);
aclError aclrtSynchronizeDevice(void);
aclError aclrtSetTsDevice(aclrtTsId tsId);
aclError aclrtGetDeviceUtilizationRate(int32_t deviceId, aclrtUtilizationInfo *utilizationInfo);
aclError aclrtGetDeviceCount(uint32_t *count);
aclError aclrtCreateEvent(aclrtEvent *event);
aclError aclrtCreateEventWithFlag(aclrtEvent *event, uint32_t flag);
aclError aclrtCreateEventExWithFlag(aclrtEvent *event, uint32_t flag);
aclError aclrtDestroyEvent(aclrtEvent event);
aclError aclrtRecordEvent(aclrtEvent event, aclrtStream stream);
aclError aclrtResetEvent(aclrtEvent event, aclrtStream stream);
aclError aclrtQueryEvent(aclrtEvent event, aclrtEventStatus *status);
aclError aclrtQueryEventStatus(aclrtEvent event, aclrtEventRecordedStatus *status);
aclError aclrtQueryEventWaitStatus(aclrtEvent event, aclrtEventWaitStatus *status);
aclError aclrtSynchronizeEvent(aclrtEvent event);
aclError aclrtSynchronizeEventWithTimeout(aclrtEvent event, int32_t timeout);
aclError aclrtEventElapsedTime(float *ms, aclrtEvent startEvent, aclrtEvent endEvent);
aclError aclrtMalloc(void **devPtr, size_t size, aclrtMemMallocPolicy policy);
aclError aclrtMallocAlign32(void **devPtr, size_t size, aclrtMemMallocPolicy policy);
aclError aclrtMallocCached(void **devPtr, size_t size, aclrtMemMallocPolicy policy);
aclError aclrtMemFlush(void *devPtr, size_t size);
aclError aclrtMemInvalidate(void *devPtr, size_t size);
aclError aclrtFree(void *devPtr);
aclError aclrtMallocHost(void **hostPtr, size_t size);
aclError aclrtFreeHost(void *hostPtr);
aclError aclrtMemcpy(void *dst, size_t destMax, const void *src, size_t count, aclrtMemcpyKind kind);
aclError aclrtMemset(void *devPtr, size_t maxCount, int32_t value, size_t count);
aclError aclrtMemcpyAsync(void *dst, size_t destMax, const void *src, size_t count, aclrtMemcpyKind kind, aclrtStream stream);
aclError aclrtMemcpy2d(void *dst, size_t dpitch, const void *src, size_t spitch, size_t width, size_t height, aclrtMemcpyKind kind);
aclError aclrtMemcpy2dAsync(void *dst, size_t dpitch, const void *src, size_t spitch, size_t width, size_t height, aclrtMemcpyKind kind, aclrtStream stream);
aclError aclrtMemsetAsync(void *devPtr, size_t maxCount, int32_t value, size_t count, aclrtStream stream);
aclError aclrtReserveMemAddress(void **virPtr, size_t size, size_t alignment, void *expectPtr, uint64_t flags);
aclError aclrtReleaseMemAddress(void *virPtr);
aclError aclrtMallocPhysical(aclrtDrvMemHandle *handle, size_t size, const aclrtPhysicalMemProp *prop, uint64_t flags);
aclError aclrtFreePhysical(aclrtDrvMemHandle handle);
aclError aclrtMapMem(void *virPtr, size_t size, size_t offset, aclrtDrvMemHandle handle, uint64_t flags);
aclError aclrtUnmapMem(void *virPtr);
aclrtStreamConfigHandle *aclrtCreateStreamConfigHandle(void);
aclError aclrtDestroyStreamConfigHandle(aclrtStreamConfigHandle *handle);
aclError aclrtSetStreamConfigOpt(aclrtStreamConfigHandle *handle, aclrtStreamConfigAttr attr, const void *attrValue, size_t valueSize);
aclError aclrtCreateStream(aclrtStream *stream);
aclError aclrtCreateStreamV2(aclrtStream *stream, const aclrtStreamConfigHandle *handle);
aclError aclrtCreateStreamWithConfig(aclrtStream *stream, uint32_t priority, uint32_t flag);
aclError aclrtDestroyStream(aclrtStream stream);
aclError aclrtDestroyStreamForce(aclrtStream stream);
aclError aclrtSynchronizeStream(aclrtStream stream);
aclError aclrtSynchronizeStreamWithTimeout(aclrtStream stream, int32_t timeout);
aclError aclrtStreamQuery(aclrtStream stream, aclrtStreamStatus *status);
aclError aclrtStreamWaitEvent(aclrtStream stream, aclrtEvent event);
aclError aclrtSetGroup(int32_t groupId);
aclError aclrtGetGroupCount(uint32_t *count);
aclrtGroupInfo *aclrtCreateGroupInfo();
aclError aclrtDestroyGroupInfo(aclrtGroupInfo *groupInfo);
aclError aclrtGetAllGroupInfo(aclrtGroupInfo *groupInfo);
aclError aclrtGetGroupInfoDetail(const aclrtGroupInfo *groupInfo, int32_t groupIndex, aclrtGroupAttr attr, void *attrValue, size_t valueLen, size_t *paramRetSize);
aclError aclrtDeviceCanAccessPeer(int32_t *canAccessPeer, int32_t deviceId, int32_t peerDeviceId);
aclError aclrtDeviceEnablePeerAccess(int32_t peerDeviceId, uint32_t flags);
aclError aclrtDeviceDisablePeerAccess(int32_t peerDeviceId);
aclError aclrtGetMemInfo(aclrtMemAttr attr, size_t *free, size_t *total);
aclError aclrtSetOpWaitTimeout(uint32_t timeout);
aclError aclrtSetOpExecuteTimeOut(uint32_t timeout);
aclError aclrtSetStreamOverflowSwitch(aclrtStream stream, uint32_t flag);
aclError aclrtGetStreamOverflowSwitch(aclrtStream stream, uint32_t *flag);
aclError aclrtSetDeviceSatMode(aclrtFloatOverflowMode mode);
aclError aclrtGetDeviceSatMode(aclrtFloatOverflowMode *mode);
aclError aclrtGetOverflowStatus(void *outputAddr, size_t outputSize, aclrtStream stream);
aclError aclrtResetOverflowStatus(aclrtStream stream);
aclError aclrtSubscribeHostFunc(uint64_t hostFuncThreadId, aclrtStream exeStream);
aclError aclrtProcessHostFunc(int32_t timeout);
aclError aclrtUnSubscribeHostFunc(uint64_t hostFuncThreadId, aclrtStream exeStream);
aclError aclrtQueryDeviceStatus(int32_t deviceId, aclrtDeviceStatus *deviceStatus);
aclrtBinary aclrtCreateBinary(const void *data, size_t dataLen);
aclError aclrtDestroyBinary(aclrtBinary binary);
aclError aclrtBinaryLoad(const aclrtBinary binary, aclrtBinHandle *binHandle);
aclError aclrtBinaryUnLoad(aclrtBinHandle binHandle);
aclError aclrtBinaryGetFunction(const aclrtBinHandle binHandle, const char *kernelName, aclrtFuncHandle *funcHandle);
aclError aclrtLaunchKernel(aclrtFuncHandle funcHandle, uint32_t blockDim, const void *argsData, size_t argsSize, aclrtStream stream);
aclError aclrtMemExportToShareableHandle(aclrtDrvMemHandle handle, aclrtMemHandleType handleType, uint64_t flags, uint64_t *shareableHandle);
aclError aclrtMemImportFromShareableHandle(uint64_t shareableHandle, int32_t deviceId, aclrtDrvMemHandle *handle);
aclError aclrtMemSetPidToShareableHandle(uint64_t shareableHandle, int32_t *pid, size_t pidNum);
aclError aclrtMemGetAllocationGranularity(aclrtPhysicalMemProp *prop, aclrtMemGranularityOptions option, size_t *granularity);
aclError aclrtDeviceGetBareTgid(int32_t *pid);
static const int ACL_COMPILE_FLAG_BIN_SELECTOR = 1;
aclError aclopSetModelDir(const char *modelDir);
aclError aclopLoad(const void *model, size_t modelSize);
aclopAttr *aclopCreateAttr();
void aclopDestroyAttr(const aclopAttr *attr);
aclError aclopSetAttrBool(aclopAttr *attr, const char *attrName, uint8_t attrValue);
aclError aclopSetAttrInt(aclopAttr *attr, const char *attrName, int64_t attrValue);
aclError aclopSetAttrFloat(aclopAttr *attr, const char *attrName, float attrValue);
aclError aclopSetAttrString(aclopAttr *attr, const char *attrName, const char *attrValue);
aclError aclopSetAttrDataType(aclopAttr *attr, const char *attrName, aclDataType attrValue);
aclError aclopSetAttrListDataType(aclopAttr *attr, const char *attrName, int numValues, const aclDataType values[]);
aclError aclopSetAttrListBool(aclopAttr *attr, const char *attrName, int numValues, const uint8_t *values);
aclError aclopSetAttrListInt(aclopAttr *attr, const char *attrName, int numValues, const int64_t *values);
aclError aclopSetAttrListFloat(aclopAttr *attr, const char *attrName, int numValues, const float *values);
aclError aclopSetAttrListString(aclopAttr *attr, const char *attrName, int numValues, const char **values);
aclError aclopSetAttrListListInt(aclopAttr *attr, const char *attrName, int numLists, const int *numValues, const int64_t *const values[]);
aclError aclopExecute(const char *opType, int numInputs, const aclTensorDesc *const inputDesc[], const aclDataBuffer *const inputs[], int numOutputs, const aclTensorDesc *const outputDesc[], aclDataBuffer *const outputs[], const aclopAttr *attr, aclrtStream stream);
aclError aclopExecuteV2(const char *opType, int numInputs, aclTensorDesc *inputDesc[], aclDataBuffer *inputs[], int numOutputs, aclTensorDesc *outputDesc[], aclDataBuffer *outputs[], aclopAttr *attr, aclrtStream stream);
aclError aclopCreateHandle(const char *opType, int numInputs, const aclTensorDesc *const inputDesc[], int numOutputs, const aclTensorDesc *const outputDesc[], const aclopAttr *opAttr, aclopHandle **handle);
void aclopDestroyHandle(aclopHandle *handle);
aclError aclopExecWithHandle(aclopHandle *handle, int numInputs, const aclDataBuffer *const inputs[], int numOutputs, aclDataBuffer *const outputs[], aclrtStream stream);
aclError aclopCast(const aclTensorDesc *srcDesc, const aclDataBuffer *srcBuffer, const aclTensorDesc *dstDesc, aclDataBuffer *dstBuffer, uint8_t truncate, aclrtStream stream);
aclError aclopCreateHandleForCast(aclTensorDesc *srcDesc, aclTensorDesc *dstDesc, uint8_t truncate, aclopHandle **handle);
aclError aclopCreateKernel(const char *opType, const char *kernelId, const char *kernelName, void *binData, int binSize, aclopEngineType enginetype, aclDataDeallocator deallocator);
aclError aclopRegisterCompileFunc(const char *opType, aclopCompileFunc func);
aclError aclopUnregisterCompileFunc(const char *opType);
aclError aclopSetKernelArgs(aclopKernelDesc *kernelDesc, const char *kernelId, uint32_t blockDim, const void *args, uint32_t argSize);
aclError aclopSetKernelWorkspaceSizes(aclopKernelDesc *kernelDesc, int numWorkspaces, size_t *workspaceSizes);
aclError aclopUpdateParams(const char *opType, int numInputs, const aclTensorDesc *const inputDesc[], int numOutputs, const aclTensorDesc *const outputDesc[], const aclopAttr *attr);
aclError aclopInferShape(const char *opType, int numInputs, aclTensorDesc *inputDesc[], aclDataBuffer *inputs[], int numOutputs, aclTensorDesc *outputDesc[], aclopAttr *attr);
aclError aclopStartDumpArgs(uint32_t dumpType, const char *path);
aclError aclopStopDumpArgs(uint32_t dumpType);
aclmdlDesc *aclmdlCreateDesc();
aclError aclmdlDestroyDesc(aclmdlDesc *modelDesc);
aclError aclmdlGetDesc(aclmdlDesc *modelDesc, uint32_t modelId);
aclError aclmdlGetDescFromFile(aclmdlDesc *modelDesc, const char *modelPath);
aclError aclmdlGetDescFromMem(aclmdlDesc *modelDesc, const void *model, size_t modelSize);
size_t aclmdlGetNumInputs(aclmdlDesc *modelDesc);
size_t aclmdlGetNumOutputs(aclmdlDesc *modelDesc);
size_t aclmdlGetInputSizeByIndex(aclmdlDesc *modelDesc, size_t index);
size_t aclmdlGetOutputSizeByIndex(aclmdlDesc *modelDesc, size_t index);
aclmdlExecConfigHandle *aclmdlCreateExecConfigHandle();
aclError aclmdlDestroyExecConfigHandle(const aclmdlExecConfigHandle *handle);
aclmdlDataset *aclmdlCreateDataset();
aclError aclmdlDestroyDataset(const aclmdlDataset *dataset);
aclError aclmdlAddDatasetBuffer(aclmdlDataset *dataset, aclDataBuffer *dataBuffer);
aclError aclmdlSetDatasetTensorDesc(aclmdlDataset *dataset, aclTensorDesc *tensorDesc, size_t index);
aclTensorDesc *aclmdlGetDatasetTensorDesc(const aclmdlDataset *dataset, size_t index);
size_t aclmdlGetDatasetNumBuffers(const aclmdlDataset *dataset);
aclDataBuffer *aclmdlGetDatasetBuffer(const aclmdlDataset *dataset, size_t index);
aclError aclmdlLoadFromFile(const char *modelPath, uint32_t *modelId);
aclError aclmdlLoadFromMem(const void *model, size_t modelSize, uint32_t *modelId);
aclError aclmdlLoadFromFileWithMem(const char *modelPath, uint32_t *modelId, void *workPtr, size_t workSize, void *weightPtr, size_t weightSize);
aclError aclmdlLoadFromMemWithMem(const void *model, size_t modelSize, uint32_t *modelId, void *workPtr, size_t workSize, void *weightPtr, size_t weightSize);
aclError aclmdlLoadFromFileWithQ(const char *modelPath, uint32_t *modelId, const uint32_t *inputQ, size_t inputQNum, const uint32_t *outputQ, size_t outputQNum);
aclError aclmdlLoadFromMemWithQ(const void *model, size_t modelSize, uint32_t *modelId, const uint32_t *inputQ, size_t inputQNum, const uint32_t *outputQ, size_t outputQNum);
aclError aclmdlExecute(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output);
aclError aclmdlExecuteV2(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output, aclrtStream stream, const aclmdlExecConfigHandle *handle);
aclError aclmdlExecuteAsyncV2(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output, aclrtStream stream, const aclmdlExecConfigHandle *handle);
aclError aclmdlExecuteAsync(uint32_t modelId, const aclmdlDataset *input, aclmdlDataset *output, aclrtStream stream);
aclError aclmdlUnload(uint32_t modelId);
aclError aclmdlQuerySize(const char *fileName, size_t *workSize, size_t *weightSize);
aclError aclmdlQueryExeOMDesc(const char *fileName, aclmdlExeOMDesc *mdlPartitionSize);
aclError aclmdlQuerySizeFromMem(const void *model, size_t modelSize, size_t *workSize, size_t *weightSize);
aclError aclmdlSetDynamicBatchSize(uint32_t modelId, aclmdlDataset *dataset, size_t index, uint64_t batchSize);
aclError aclmdlSetDynamicHWSize(uint32_t modelId, aclmdlDataset *dataset, size_t index, uint64_t height, uint64_t width);
aclError aclmdlSetInputDynamicDims(uint32_t modelId, aclmdlDataset *dataset, size_t index, const aclmdlIODims *dims);
aclError aclmdlGetInputDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);
aclError aclmdlGetInputDimsV2(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);
aclError aclmdlGetOutputDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);
aclError aclmdlGetCurOutputDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims);
const char *aclmdlGetOpAttr(aclmdlDesc *modelDesc, const char *opName, const char *attr);
const char *aclmdlGetInputNameByIndex(const aclmdlDesc *modelDesc, size_t index);
const char *aclmdlGetOutputNameByIndex(const aclmdlDesc *modelDesc, size_t index);
aclFormat aclmdlGetInputFormat(const aclmdlDesc *modelDesc, size_t index);
aclFormat aclmdlGetOutputFormat(const aclmdlDesc *modelDesc, size_t index);
aclDataType aclmdlGetInputDataType(const aclmdlDesc *modelDesc, size_t index);
aclDataType aclmdlGetOutputDataType(const aclmdlDesc *modelDesc, size_t index);
aclError aclmdlGetInputIndexByName(const aclmdlDesc *modelDesc, const char *name, size_t *index);
aclError aclmdlGetOutputIndexByName(const aclmdlDesc *modelDesc, const char *name, size_t *index);
aclError aclmdlGetDynamicBatch(const aclmdlDesc *modelDesc, aclmdlBatch *batch);
aclError aclmdlGetDynamicHW(const aclmdlDesc *modelDesc, size_t index, aclmdlHW *hw);
aclError aclmdlGetInputDynamicGearCount(const aclmdlDesc *modelDesc, size_t index, size_t *gearCount);
aclError aclmdlGetInputDynamicDims(const aclmdlDesc *modelDesc, size_t index, aclmdlIODims *dims, size_t gearCount);
aclmdlAIPP *aclmdlCreateAIPP(uint64_t batchSize);
aclError aclmdlDestroyAIPP(const aclmdlAIPP *aippParmsSet);
aclError aclmdlGetAippDataSize(uint64_t batchSize, size_t *size);
aclError aclmdlSetAIPPInputFormat(aclmdlAIPP *aippParmsSet, aclAippInputFormat inputFormat);
aclError aclmdlSetAIPPCscParams(aclmdlAIPP *aippParmsSet, int8_t cscSwitch, int16_t cscMatrixR0C0, int16_t cscMatrixR0C1, int16_t cscMatrixR0C2, int16_t cscMatrixR1C0, int16_t cscMatrixR1C1, int16_t cscMatrixR1C2, int16_t cscMatrixR2C0, int16_t cscMatrixR2C1, int16_t cscMatrixR2C2, uint8_t cscOutputBiasR0, uint8_t cscOutputBiasR1, uint8_t cscOutputBiasR2, uint8_t cscInputBiasR0, uint8_t cscInputBiasR1, uint8_t cscInputBiasR2);
aclError aclmdlSetAIPPRbuvSwapSwitch(aclmdlAIPP *aippParmsSet, int8_t rbuvSwapSwitch);
aclError aclmdlSetAIPPAxSwapSwitch(aclmdlAIPP *aippParmsSet, int8_t axSwapSwitch);
aclError aclmdlSetAIPPSrcImageSize(aclmdlAIPP *aippParmsSet, int32_t srcImageSizeW, int32_t srcImageSizeH);
aclError aclmdlSetAIPPScfParams(aclmdlAIPP *aippParmsSet, int8_t scfSwitch, int32_t scfInputSizeW, int32_t scfInputSizeH, int32_t scfOutputSizeW, int32_t scfOutputSizeH, uint64_t batchIndex);
aclError aclmdlSetAIPPCropParams(aclmdlAIPP *aippParmsSet, int8_t cropSwitch, int32_t cropStartPosW, int32_t cropStartPosH, int32_t cropSizeW, int32_t cropSizeH, uint64_t batchIndex);
aclError aclmdlSetAIPPPaddingParams(aclmdlAIPP *aippParmsSet, int8_t paddingSwitch, int32_t paddingSizeTop, int32_t paddingSizeBottom, int32_t paddingSizeLeft, int32_t paddingSizeRight, uint64_t batchIndex);
aclError aclmdlSetAIPPDtcPixelMean(aclmdlAIPP *aippParmsSet, int16_t dtcPixelMeanChn0, int16_t dtcPixelMeanChn1, int16_t dtcPixelMeanChn2, int16_t dtcPixelMeanChn3, uint64_t batchIndex);
aclError aclmdlSetAIPPDtcPixelMin(aclmdlAIPP *aippParmsSet, float dtcPixelMinChn0, float dtcPixelMinChn1, float dtcPixelMinChn2, float dtcPixelMinChn3, uint64_t batchIndex);
aclError aclmdlSetAIPPPixelVarReci(aclmdlAIPP *aippParmsSet, float dtcPixelVarReciChn0, float dtcPixelVarReciChn1, float dtcPixelVarReciChn2, float dtcPixelVarReciChn3, uint64_t batchIndex);
aclError aclmdlSetInputAIPP(uint32_t modelId, aclmdlDataset *dataset, size_t index, const aclmdlAIPP *aippParmsSet);
aclError aclmdlSetAIPPByInputIndex(uint32_t modelId, aclmdlDataset *dataset, size_t index, const aclmdlAIPP *aippParmsSet);
aclError aclmdlGetAippType(uint32_t modelId, size_t index, aclmdlInputAippType *type, size_t *dynamicAttachedDataIndex);
aclError aclmdlGetFirstAippInfo(uint32_t modelId, size_t index, aclAippInfo *aippInfo);
aclError aclmdlCreateAndGetOpDesc(uint32_t deviceId, uint32_t streamId, uint32_t taskId, char *opName, size_t opNameLen, aclTensorDesc **inputDesc, size_t *numInputs, aclTensorDesc **outputDesc, size_t *numOutputs);
aclError aclmdlInitDump();
aclError aclmdlSetDump(const char *dumpCfgPath);
aclError aclmdlFinalizeDump();
aclError aclmdlLoadWithConfig(const aclmdlConfigHandle *handle, uint32_t *modelId);
aclmdlConfigHandle *aclmdlCreateConfigHandle();
aclError aclmdlDestroyConfigHandle(aclmdlConfigHandle *handle);
aclError aclmdlSetConfigOpt(aclmdlConfigHandle *handle, aclmdlConfigAttr attr, const void *attrValue, size_t valueSize);
aclError aclmdlSetExecConfigOpt(aclmdlExecConfigHandle *handle, aclmdlExecConfigAttr attr, const void *attrValue, size_t valueSize);
const char *aclmdlGetTensorRealName(const aclmdlDesc *modelDesc, const char *name);
aclError aclInit(const char *configPath);
aclError aclFinalize();
aclError aclrtGetVersion(int32_t *majorVersion, int32_t *minorVersion, int32_t *patchVersion);
const char *aclGetRecentErrMsg();
aclnnStatus aclnnAllGatherMatmulGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const char* group, int64_t gatherIndex, int64_t commTurn, int64_t streamMode, const aclTensor* output, const aclTensor* gatherOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAllGatherMatmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAmaxGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAminGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAmin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAminmaxGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, aclTensor* minOut, aclTensor* maxOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAminmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAminmaxAllGetWorkspaceSize(const aclTensor* self, aclTensor* minOut, aclTensor* maxOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAminmaxAll(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAminmaxDimGetWorkspaceSize(const aclTensor* self, const int64_t dim, bool keepDim, aclTensor* minOut, aclTensor* maxOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAminmaxDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAnyGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAny(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnArangeGetWorkspaceSize(const aclScalar* start, const aclScalar* end, const aclScalar* step, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnArange(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnArgMaxGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnArgMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnArgMinGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnArgMin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnArgsortGetWorkspaceSize(const aclTensor* self, int64_t dim, bool descending, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnArgsort(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAsinGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAsin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAsinGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAsin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAsinhGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAsinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAsinhGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAsinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAtanGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAtan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceAtanGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAtan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAtan2GetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAtan2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAtan2GetWorkspaceSize(aclTensor* selfRef, aclTensor* other, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAtan2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAtanhGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceAtanhGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceAtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAvgPool2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize, const aclIntArray* strides, const aclIntArray* paddings, const bool ceilMode, const bool countIncludePad, const int64_t divisorOverride, const int8_t cubeMathType, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAvgPool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBaddbmmGetWorkspaceSize(const aclTensor* self, const aclTensor* batch1, const aclTensor* batch2, const aclScalar* beta, const aclScalar* alpha, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBaddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBaddbmmGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* batch1, const aclTensor* batch2, const aclScalar* beta, const aclScalar* alpha, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBaddbmm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBatchMatMulGetWorkspaceSize(const aclTensor* self, const aclTensor* mat2, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchMatMul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBatchNormGetWorkspaceSize(const aclTensor* input, const aclTensor* weight, const aclTensor* bias, aclTensor* runningMean, aclTensor* runningVar, bool training, double momentum, double eps, aclTensor* output, aclTensor* saveMean, aclTensor* saveInvstd, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBincountGetWorkspaceSize(const aclTensor* self, const aclTensor* weights, int64_t minlength, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBincount(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseAndScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseAndScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBitwiseAndScalarGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBitwiseAndScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseAndTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseAndTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBitwiseAndTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBitwiseAndTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseNotGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseNot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseOrScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseOrScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBitwiseOrScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBitwiseOrScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseOrTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseOrTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBitwiseOrTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBitwiseOrTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseXorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseXorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBitwiseXorScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBitwiseXorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBitwiseXorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBitwiseXorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceBitwiseXorTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceBitwiseXorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCastGetWorkspaceSize(const aclTensor* self, const aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCast(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCeilGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCeil(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceCeilGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceCeil(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnCatGetWorkspaceSize(const aclTensorList* tensors, int64_t dim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnCeluGetWorkspaceSize(const aclTensor* self, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceCeluGetWorkspaceSize(aclTensor* selfRef, const aclScalar* alpha, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceCelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnChannelShuffleGetWorkspaceSize(const aclTensor* self, int64_t groups, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnChannelShuffle(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnClampGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMin, const aclScalar* clipValueMax, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnClamp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnClampMinGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMin, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnClampMin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnClampTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* clipValueMin, const aclTensor* clipValueMax, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnClampMinTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* clipValueMin, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnClampMinTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceClampMinTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* clipValueMin, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceClampMinTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnClampTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnClampMaxGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMax, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnClampMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceClampMaxGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* clipValueMax, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceClampMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnClampMaxTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* max, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceClampMaxTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* max, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnClampMaxTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceClampMaxTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnComplexGetWorkspaceSize(const aclTensor* real, const aclTensor* imag, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnComplex(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnConstantPadNdGetWorkspaceSize(const aclTensor* self, const aclIntArray* pad, const aclScalar* value, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnConstantPadNd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnConvolutionGetWorkspaceSize(const aclTensor* input, const aclTensor* weight, const aclTensor* bias, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool transposed, const aclIntArray* outputPadding, const int64_t groups, aclTensor* output, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnConvTbcGetWorkspaceSize(const aclTensor* self, const aclTensor* weight, const aclTensor* bias, const int64_t pad, aclTensor* output, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnConvDepthwise2dGetWorkspaceSize(const aclTensor* self, const aclTensor* weight, const aclIntArray* kernelSize, const aclTensor* bias, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnConvolution(void* workspace, const uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnConvTbc(void* workspace, const uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnConvDepthwise2d(void* workspace, const uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCosGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceCosGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceCos(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnCoshGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceCoshGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceCosh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCummaxGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCummax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCumminGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCummin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCumsumGetWorkspaceSize(const aclTensor* self, int64_t dim, aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCumsum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCumsumV2GetWorkspaceSize(const aclTensor* self, int64_t dim, bool exclusive, bool reverse, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCumsumV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDiagGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDiag(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDiagFlatGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDiagFlat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDivGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDivsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDivModGetWorkspaceSize(const aclTensor* self, const aclTensor* other, int mode, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDivModsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, int mode, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceDivGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceDivsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceDivModGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, int mode, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceDivModsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, int mode, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDivs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDivMod(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDivMods(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceDiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceDivs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceDivMod(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceDivMods(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDotGetWorkspaceSize(const aclTensor* self, const aclTensor* tensor, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEluGetWorkspaceSize(const aclTensor* self, const aclScalar* alpha, const aclScalar* scale, const aclScalar* inputScale, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnElu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceEluGetWorkspaceSize(aclTensor* selfRef, const aclScalar* alpha, const aclScalar* scale, const aclScalar* inputScale, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceElu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEmbeddingGetWorkspaceSize(const aclTensor* weight, const aclTensor* indices, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEmbedding(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnEmbeddingRenormGetWorkspaceSize(aclTensor* selfRef, const aclTensor* indices, double maxNorm, double normType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEmbeddingRenorm(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnEmbeddingBagGetWorkspaceSize(const aclTensor* weight, const aclTensor* indices, const aclTensor* offsets, bool scaleGradByFreq, int64_t mode, bool sparse, const aclTensor* perSampleWeights, bool includeLastOffset, int64_t paddingIdx, aclTensor* output, aclTensor* offset2bag, aclTensor* bagSize, aclTensor* maxIndices, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEmbeddingBag(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEqScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEqScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceEqScalarGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceEqScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEqTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEqTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceEqTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceEqTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEqualGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEqual(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnErfGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnErf(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceErfGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceErf(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnErfcGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnErfc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceErfcGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceErfc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnErfinvGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnErfinv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceErfinvGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceErfinv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnExpGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceExpGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnExp2GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnExp2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceExp2GetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceExp2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnExpandGetWorkspaceSize(const aclTensor* self, const aclIntArray* size, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnExpand(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnExpm1GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnExpm1(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceExpm1GetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceExpm1(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnEyeGetWorkspaceSize(int64_t n, int64_t m, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEye(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus
aclnnFFNGetWorkspaceSize(const aclTensor *x, const aclTensor *weight1, const aclTensor *weight2, const aclIntArray *expertTokens, const aclTensor *bias1, const aclTensor *bias2, const aclTensor *scale, const aclTensor *offset, const aclTensor *deqScale1, const aclTensor *deqScale2, const aclTensor *antiquantScale1, const aclTensor *antiquantScale2, const aclTensor *antiquantOffset1, const aclTensor *antiquantOffset2, const char *activation, int64_t innerPrecise, const aclTensor *y, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFFN(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, aclrtStream stream);
aclnnStatus aclnnFlashAttentionScoreGetWorkspaceSize( const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *realShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclIntArray *prefixOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, const aclTensor *softmaxMaxOut, const aclTensor *softmaxSumOut, const aclTensor *softmaxOutOut, const aclTensor *attentionOutOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionScore(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionVarLenScoreGetWorkspaceSize( const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *realShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclIntArray *prefixOptional, const aclIntArray *actualSeqQLenOptional, const aclIntArray *actualSeqKvLenOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, const aclTensor *softmaxMaxOut, const aclTensor *softmaxSumOut, const aclTensor *softmaxOutOut, const aclTensor *attentionOutOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionVarLenScore(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionScoreV2GetWorkspaceSize( const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *realShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclIntArray *prefixOptional, const aclIntArray *qStartIdxOptional, const aclIntArray *kvStartIdxOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, int64_t pseTypeOptional, const aclTensor *softmaxMaxOut, const aclTensor *softmaxSumOut, const aclTensor *softmaxOutOut, const aclTensor *attentionOutOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionScoreV2( void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionVarLenScoreV2GetWorkspaceSize( const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *realShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclIntArray *prefixOptional, const aclIntArray *actualSeqQLenOptional, const aclIntArray *actualSeqKvLenOptional, const aclIntArray *qStartIdxOptional, const aclIntArray *kvStartIdxOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, int64_t pseTypeOptional, const aclTensor *softmaxMaxOut, const aclTensor *softmaxSumOut, const aclTensor *softmaxOutOut, const aclTensor *attentionOutOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionVarLenScoreV2( void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlattenGetWorkspaceSize(const aclTensor* self, int64_t axis, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFlatten(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnFlipGetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFlip(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnFloorGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFloor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFloorGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFloor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnFloorDivideGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFloorDividesGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFloorDivideGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFloorDividesGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFloorDivide(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnFloorDivides(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFloorDivide(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFloorDivides(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnFmodScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFmodScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFmodScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFmodScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnFmodTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFmodTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFmodTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFmodTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnFracGetWorkspaceSize(const aclTensor* input, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnFrac(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFracGetWorkspaceSize(aclTensor* inputRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFrac(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGatherGetWorkspaceSize(const aclTensor* self, const int64_t dim, const aclTensor* index, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGather(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGatherV2GetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGatherV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeGluGetWorkspaceSize(const aclTensor* self, int64_t dim, int64_t approximate, aclTensor* out, aclTensor* outGelu, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeGluV3GetWorkspaceSize(const aclTensor* self, int64_t dim, int64_t approximate, bool activateLeft, aclTensor* out, aclTensor* outGelu, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeGlu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeGluV3(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeluGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGemmGetWorkspaceSize(const aclTensor* A, const aclTensor* B, const aclTensor* C, float alpha, float beta, int64_t transA, int64_t transB, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGemm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGerGetWorkspaceSize(const aclTensor* self, const aclTensor* vec2, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGer(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceGeScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceGeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceGeTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceGeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGluGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGlu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGridSampler2DGetWorkspaceSize(const aclTensor* input, const aclTensor* grid, int64_t interpolationMode, int64_t paddingMode, bool alignCorners, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGridSampler2D(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGridSampler3DGetWorkspaceSize(const aclTensor* input, const aclTensor* grid, int64_t interpolationMode, int64_t paddingMode, bool alignCorners, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGridSampler3D(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGroupNormGetWorkspaceSize(const aclTensor* self, const aclTensor* gamma, const aclTensor* beta, int64_t N, int64_t C, int64_t HxW, int64_t group, double eps, aclTensor* out, aclTensor* meanOut, aclTensor* rstdOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGroupNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGroupNormSiluGetWorkspaceSize(const aclTensor* self, const aclTensor* gamma, const aclTensor* beta, int64_t group, double eps, aclTensor* out, aclTensor* meanOut, aclTensor* rstdOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGroupNormSilu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGroupNormSiluV2GetWorkspaceSize(const aclTensor* self, const aclTensor* gamma, const aclTensor* beta, int64_t group, double eps, bool activateSilu, aclTensor* out, aclTensor* meanOut, aclTensor* rstdOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGroupNormSiluV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGtScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceGtScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceGtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGtTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceGtTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceGtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnHardshrinkGetWorkspaceSize(const aclTensor* self, const aclScalar* lambd, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardshrink(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnHardsigmoidGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardsigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceHardsigmoidGetWorkspaceSize(const aclTensor* self, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceHardsigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnHardswishGetWorkspaceSize(const aclTensor* self, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardswish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceHardswishGetWorkspaceSize(const aclTensor* self, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceHardswish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnHardtanhGetWorkspaceSize(const aclTensor* self, const aclScalar* clipValueMin, const aclScalar* clipValueMax, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceHardtanhGetWorkspaceSize(aclTensor* selfRef, const aclScalar* clipValueMin, const aclScalar* clipValueMax, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceHardtanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnHistcGetWorkspaceSize(const aclTensor* self, int64_t bins, const aclScalar* min, const aclScalar* max, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHistc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIm2colGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize, const aclIntArray* dilation, const aclIntArray* padding, const aclIntArray* stride, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIm2col(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIncreFlashAttentionGetWorkspaceSize( const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift, const aclTensor *attenMask, const aclIntArray *actualSeqLengths, int64_t numHeads, double scaleValue, char *inputLayout, int64_t numKeyValueHeads, const aclTensor *attentionOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnIncreFlashAttention(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnIncreFlashAttentionV2GetWorkspaceSize( const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift, const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclTensor *dequantScale1, const aclTensor *quantScale1, const aclTensor *dequantScale2, const aclTensor *quantScale2, const aclTensor *quantOffset2, int64_t numHeads, double scaleValue, char *inputLayout, int64_t numKeyValueHeads, const aclTensor *attentionOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnIncreFlashAttentionV2(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnIncreFlashAttentionV3GetWorkspaceSize( const aclTensor *query, const aclTensorList *key, const aclTensorList *value, const aclTensor *pseShift, const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclTensor *dequantScale1, const aclTensor *quantScale1, const aclTensor *dequantScale2, const aclTensor *quantScale2, const aclTensor *quantOffset2, const aclTensor *antiquantScale, const aclTensor *antiquantOffset, const aclTensor *blocktable, int64_t numHeads, double scaleValue, char *inputLayout, int64_t numKeyValueHeads, int64_t blockSize, int64_t innerPrecise, const aclTensor *attentionOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnIncreFlashAttentionV3(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnIndex(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnIndexGetWorkspaceSize(const aclTensor* self, const aclTensorList* indices, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIndexAddGetWorkspaceSize(const aclTensor* self, const int64_t dim, const aclTensor* index, const aclTensor* source, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIndexAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIndexFillTensorGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclIntArray* index, const aclScalar* value, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIndexFillTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceIndexFillTensorGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclIntArray* index, const aclScalar* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceIndexFillTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIndexPutImplGetWorkspaceSize(aclTensor* selfRef, const aclTensorList* indices, const aclTensor* values, const bool accumulate, const bool unsafe, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIndexPutImpl(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIndexSelectGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIndexSelect(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInverseGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInverse(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIsCloseGetWorkspaceSize(const aclTensor* self, const aclTensor* other, double rtol, double atol, bool equal_nan, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIsClose(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIsInTensorScalarGetWorkspaceSize(const aclTensor* element, const aclScalar* testElement, bool assumeUnique, bool invert, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIsInTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnKthvalueGetWorkspaceSize(const aclTensor* self, int64_t k, int64_t dim, bool keepdim, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnKthvalue(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnLayerNormGetWorkspaceSize(const aclTensor* input, const aclIntArray* normalizedShape, const aclTensor* weightOptional, const aclTensor* biasOptional, double eps, aclTensor* out, aclTensor* meanOutOptional, aclTensor* rstdOutOptional, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLayerNormWithImplModeGetWorkspaceSize( const aclTensor* input, const aclIntArray* normalizedShape, const aclTensor* weightOptional, const aclTensor* biasOptional, double eps, aclTensor* out, aclTensor* meanOutOptional, aclTensor* rstdOutOptional, int32_t implMode, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLayerNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLayerNormWithImplMode(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLeakyReluGetWorkspaceSize(const aclTensor* self, const aclScalar* negativeSlope, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLeakyRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLeakyReluGetWorkspaceSize(aclTensor* selfRef, const aclScalar* negativeSlope, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLeakyRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLeScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLeScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLeTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLeTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLinalgVectorNormGetWorkspaceSize(const aclTensor* self, const aclScalar* ord, const aclIntArray* dims, bool keepDims, const aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLinalgVectorNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLinspaceGetWorkspaceSize(const aclScalar* start, const aclScalar* end, int64_t steps, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLinspace(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLog(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLogGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLog(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLog10GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLog10(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLog10GetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLog10(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLog1pGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLog1p(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLog1pGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLog1p(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLog2GetWorkspaceSize(const aclTensor* self, const aclTensor* out, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnLog2(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLog2GetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLog2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogAddExpGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogAddExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogAddExp2GetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogAddExp2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogdetGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogdet(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogicalAndGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogicalAnd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLogicalAndGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLogicalAnd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogicalNotGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogicalNot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLogicalNotGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLogicalNot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogicalOrGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogicalOr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLogicalOrGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLogicalOr(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogicalXorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogicalXor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogSigmoidGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogSigmoidForwardGetWorkspaceSize(const aclTensor* self, aclTensor* out, aclTensor* buffer, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogSigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogSigmoidForward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogSoftmaxGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogSoftmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogSumExpGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogSumExp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLtScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLtScalarGetWorkspaceSize(const aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLtScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLtTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceLtTensorGetWorkspaceSize(const aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLtTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaskedSelectGetWorkspaceSize(const aclTensor* self, const aclTensor* mask, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaskedSelect(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMatmulGetWorkspaceSize(const aclTensor* self, const aclTensor* mat2, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMatmul(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, aclrtStream stream);
aclnnStatus aclnnMatmulCompressDequantGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2, const aclTensor* compressIndex, const aclTensor* bias, const aclTensor* deqScale, const aclTensor* offsetW, int offsetX, const aclIntArray* compressInfo, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMatmulCompressDequant(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMatmulReduceScatterGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const char* group, const char* reduceOp, int64_t commTurn, int64_t streamMode, const aclTensor* output, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMatmulReduceScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim, aclTensor* out, aclTensor* indices, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaximumGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaximum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxPool2dWithMaskGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool ceilMode, aclTensor* out, aclTensor* indices, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxPool2dWithMask(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxPool2dWithIndicesGetWorkspaceSize(const aclTensor* self, const aclIntArray* kernelSize, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool ceilMode, aclTensor* out, aclTensor* indices, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxPool2dWithIndices(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxUnpool2dGetWorkspaceSize(const aclTensor* self, const aclTensor* indices, const aclIntArray* outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxUnpool2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxUnpool3dGetWorkspaceSize(const aclTensor* self, const aclTensor* indices, const aclIntArray* outputSize, const aclIntArray* stride, const aclIntArray* padding, aclTensor* outRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxUnpool3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxV2GetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, bool keepDims, bool noopWithEmptyDims, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMeanGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMean(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMeanV2GetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, bool noopWithEmptyAxes, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMeanV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMedianGetWorkspaceSize(const aclTensor* self, aclTensor* valuesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMedian(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMedianDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepDim, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMedianDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNanMedianGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNanMedian(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNanMedianDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepDim, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNanMedianDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMinGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMinDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepdim, aclTensor* out, aclTensor* indices, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMinDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMinimumGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMinimum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMishGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceMishGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceMish(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMmGetWorkspaceSize(const aclTensor* self, const aclTensor* mat2, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMm(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, aclrtStream stream);
aclnnStatus aclnnMulsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMulGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceMulsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceMulGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMuls(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceMuls(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceMul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMvGetWorkspaceSize(const aclTensor* self, const aclTensor* vec, aclTensor* out, int8_t cubeMathType, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNeScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceNeScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceNeScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNeTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceNeTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceNeTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNegGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceNegGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNeg(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceNeg(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNonzeroGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNonzero(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNonzeroV2GetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNonzeroV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNormGetWorkspaceSize(const aclTensor* self, const aclScalar* pScalar, const aclIntArray* dim, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnOneHotGetWorkspaceSize(const aclTensor* self, int numClasses, const aclTensor* onValue, const aclTensor* offValue, int64_t axis, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnOneHot(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPdistGetWorkspaceSize(const aclTensor* self, float p, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPdist(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPermuteGetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, aclTensor* out, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnPermute(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnPowTensorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* exponent, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplacePowTensorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* exponent, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPowTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplacePowTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPreluGetWorkspaceSize(const aclTensor* self, const aclTensor* weight, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPrelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnProdGetWorkspaceSize(const aclTensor* self, const aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnProd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnProdDimGetWorkspaceSize(const aclTensor* self, int64_t dim, bool keepDim, const aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnProdDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPromptFlashAttentionGetWorkspaceSize( const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *pseShift, const aclTensor *attenMask, const aclIntArray *actualSeqLengths, int64_t numHeads, double scaleValue, int64_t preTokens, int64_t nextTokens, char *inputLayout, int64_t numKeyValueHeads, const aclTensor *attentionOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnPromptFlashAttention( void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnQuantMatmulGetWorkspaceSize(const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, float deqScale, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnQuantMatmul(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnQuantMatmulV2GetWorkspaceSize(const aclTensor* x1, const aclTensor* x2, const aclTensor* bias, const aclTensor* deqScale, bool adjX1, bool adjX2, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnQuantMatmulV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnRangeGetWorkspaceSize(const aclScalar* start, const aclScalar* end, const aclScalar* step, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRange(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRealGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReciprocalGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReciprocal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceReciprocalGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceReciprocal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReduceSumGetWorkspaceSize(const aclTensor* self, const aclIntArray* dims, bool keepDims, aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReduceSum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReflectionPad1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReflectionPad1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnReflectionPad2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReflectionPad2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnReflectionPad3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReflectionPad3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReluGetWorkspaceSize(const aclTensor* self, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceReluGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnRenormGetWorkspaceSize(const aclTensor* self, const aclScalar* p, int64_t dim, const aclScalar* maxNorm, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRenorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceRenormGetWorkspaceSize(aclTensor* selfRef, const aclScalar* p, int64_t dim, const aclScalar* maxNorm, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRenorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRepeatGetWorkspaceSize(const aclTensor* self, const aclIntArray* repeats, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRepeat(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRepeatInterleaveGetWorkspaceSize(const aclTensor* self, const aclTensor* repeats, int64_t outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRepeatInterleave(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRepeatInterleaveWithDimGetWorkspaceSize(const aclTensor* self, const aclTensor* repeats, int64_t dim, int64_t outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRepeatInterleaveWithDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRepeatInterleaveIntGetWorkspaceSize(const aclTensor* self, int64_t repeats, int64_t outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRepeatInterleaveInt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRepeatInterleaveIntWithDimGetWorkspaceSize(const aclTensor* self, int64_t repeats, int64_t dim, int64_t outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRepeatInterleaveIntWithDim(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRepeatInterleaveTensorGetWorkspaceSize(const aclTensor* repeats, int64_t outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRepeatInterleaveTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReplicationPad1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReplicationPad1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReplicationPad2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReplicationPad2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReplicationPad3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReplicationPad3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRollGetWorkspaceSize(const aclTensor* x, const aclIntArray* shifts, const aclIntArray* dims, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRoll(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRoundGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRound(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceRoundGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRound(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnRoundDecimalsGetWorkspaceSize(const aclTensor* self, int64_t decimals, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRoundDecimals(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceRoundDecimalsGetWorkspaceSize(aclTensor* selfRef, int64_t decimals, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRoundDecimals(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRReluWithNoiseGetWorkspaceSize(const aclTensor* self, const aclTensor* noise, const aclScalar* lower, const aclScalar* upper, bool training, int64_t seed, int64_t offset, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRReluWithNoiseGetWorkspaceSize(const aclTensor* self, const aclTensor* noise, const aclScalar* lower, const aclScalar* upper, bool training, int64_t seed, int64_t offset, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRReluWithNoise(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceRReluWithNoise(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnRsqrtGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRsqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceRsqrtGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRsqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRsubsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRsubs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRsubGetWorkspaceSize(const aclTensor* self, const aclTensor* other, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRsub(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnScatterGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index, const aclTensor* src, int64_t reduce, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnScatterValueGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index, const aclScalar* value, int64_t reduce, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnScatterValue(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceScatterGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index, const aclTensor* src, int64_t reduce, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceScatterValueGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index, const aclScalar* value, int64_t reduce, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceScatterValue(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnScatterAddGetWorkspaceSize(const aclTensor* self, int64_t dim, const aclTensor* index, const aclTensor* src, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnScatterAdd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSearchSortedGetWorkspaceSize(const aclTensor* sortedSequence, const aclTensor* self, const bool outInt32, const bool right, const aclTensor* sorter, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSearchSorted(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSearchSortedsGetWorkspaceSize(const aclTensor* sortedSequence, const aclScalar* self, const bool outInt32, const bool right, const aclTensor* sorter, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSearchSorteds(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSeluGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceSeluGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSelu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSigmoidGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceSigmoidGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSigmoid(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSignGetWorkspaceSize(const aclTensor* self, aclTensor* result, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSign(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSignbitGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSignbit(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSiluGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSilu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSinGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceSinGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSin(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSincGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSinc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceSincGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSinc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSinhGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceSinhGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSinh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSliceGetWorkspaceSize(const aclTensor* self, int64_t dim, int64_t start, int64_t end, int64_t step, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSlice(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSliceV2GetWorkspaceSize(const aclTensor* self, const aclIntArray* starts, const aclIntArray* ends, const aclIntArray* axes, const aclIntArray* steps, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSliceV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSlogdetGetWorkspaceSize(const aclTensor* self, aclTensor* signOut, aclTensor* logOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSlogdet(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftmaxGetWorkspaceSize(const aclTensor* self, int64_t dim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftmax(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftplusGetWorkspaceSize(const aclTensor* self, const aclScalar* beta, const aclScalar* threshold, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftplus(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSoftshrinkGetWorkspaceSize(const aclTensor* self, const aclScalar* lambd, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftshrink(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSortGetWorkspaceSize(const aclTensor* self, bool stable, int64_t dim, bool descending, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSort(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSplitTensorGetWorkspaceSize(const aclTensor* self, uint64_t splitSections, int64_t dim, aclTensorList* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSplitTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSplitWithSizeGetWorkspaceSize(const aclTensor* self, const aclIntArray* splitSize, int64_t dim, aclTensorList* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSplitWithSize(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSqrtGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** opExecutor);
aclnnStatus aclnnSqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* opExecutor, aclrtStream stream);
aclnnStatus aclnnInplaceSqrtGetWorkspaceSize(const aclTensor* self, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSqrt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnStackGetWorkspaceSize(const aclTensorList* tensors, int64_t dim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnStack(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnStdGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, const int64_t correction, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnStd(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnStdMeanCorrectionGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, int64_t correction, bool keepdim, aclTensor* stdOut, aclTensor* meanOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnStdMeanCorrection(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSubGetWorkspaceSize(const aclTensor* self, const aclTensor* other, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSub(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSubsGetWorkspaceSize(const aclTensor* self, const aclScalar* other, const aclScalar* alpha, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSubs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceSubGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, const aclScalar* alpha, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSub(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceSubsGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, const aclScalar* alpha, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceSubs(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSumGetWorkspaceSize(const aclTensorList* tensors, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSWhereGetWorkspaceSize(const aclTensor* condition, const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSWhere(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnTakeGetWorkspaceSize(const aclTensor* self, const aclTensor* index, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTake(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnTanGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceTanGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceTan(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnTanhGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceTanhGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceTanh(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnThresholdGetWorkspaceSize(const aclTensor* self, const aclScalar* threshold, const aclScalar* value, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnThreshold(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceThresholdGetWorkspaceSize(aclTensor* selfRef, const aclScalar* threshold, const aclScalar* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceThreshold(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnTopkGetWorkspaceSize(const aclTensor* self, int64_t k, int64_t dim, bool largest, bool sorted, aclTensor* valuesOut, aclTensor* indicesOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTopk(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnTraceGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTrace(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnTransQuantParam(const float* scaleArray, uint64_t scaleSize, const float* offsetArray, uint64_t offsetSize, uint64_t** quantParam, uint64_t* quantParamSize);
aclnnStatus aclnnTriangularSolveGetWorkspaceSize(const aclTensor* self, const aclTensor* A, bool upper, bool transpose, bool unitriangular, aclTensor* xOut, aclTensor* mOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTriangularSolve(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnTrilGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTril(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceTrilGetWorkspaceSize(const aclTensor* selfRef, int64_t diagonal, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceTril(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnTriuGetWorkspaceSize(const aclTensor* self, int64_t diagonal, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTriu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceTriuGetWorkspaceSize(aclTensor* selfRef, int64_t diagonal, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceTriu(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnTruncGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTrunc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceTruncGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspace_size, aclOpExecutor** executor);
aclnnStatus aclnnInplaceTrunc(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUniqueGetWorkspaceSize(const aclTensor* self, bool sorted, bool returnInverse, aclTensor* valueOut, aclTensor* inverseOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUnique(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUnique2GetWorkspaceSize(const aclTensor* self, bool sorted, bool returnInverse, bool returnCounts, aclTensor* valueOut, aclTensor* inverseOut, aclTensor* countsOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUnique2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUniqueConsecutiveGetWorkspaceSize(const aclTensor* self, bool returnInverse, bool returnCounts, int64_t dim, aclTensor* valueOut, aclTensor* inverseOut, aclTensor* countsOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUniqueConsecutive(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleBilinear2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleBilinear2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, const bool alignCorners, const double scalesH, const double scalesW, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleLinear1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleLinear1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, const bool alignCorners, const double scales, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest1dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest1d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleNearest2dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnUpsampleNearest3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, double scalesD, double scalesH, double scalesW, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleTrilinear3dGetWorkspaceSize(const aclTensor* self, const aclIntArray* outputSize, bool alignCorners, double scalesD, double scalesH, double scalesW, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleTrilinear3d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnVarGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool unbiased, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnVar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnVarCorrectionGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, int64_t correction, bool keepdim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnVarCorrection(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnVarMeanGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, int64_t correction, bool keepdim, aclTensor* varOut, aclTensor* meanOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnVarMean(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnXLogYScalarOtherGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnXLogYScalarOther(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceXLogYScalarOtherGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceXLogYScalarOther(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnXLogYScalarSelfGetWorkspaceSize(const aclScalar* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnXLogYScalarSelf(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnXLogYTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnXLogYTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceXLogYTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceXLogYTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDigammaGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDigamma(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLgammaGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLgamma(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGlobalAveragePoolGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGlobalAveragePool(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceCopyGetWorkspaceSize(aclTensor* selfRef, const aclTensor* src, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceCopy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceFillScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFillScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceFillTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceFillTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIndexCopyGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index, const aclTensor* source, aclTensor* outRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIndexCopy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceIndexCopyGetWorkspaceSize(aclTensor* selfRef, int64_t dim, const aclTensor* index, const aclTensor* source, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceIndexCopy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLerpGetWorkspaceSize(const aclTensor* self, const aclTensor* end, const aclTensor* weight, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLerp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceLerpGetWorkspaceSize(aclTensor* selfRef, const aclTensor* end, const aclTensor* weight, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLerp(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnLerpsGetWorkspaceSize(const aclTensor* self, const aclTensor* end, const aclScalar* weight, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLerps(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceLerpsGetWorkspaceSize(aclTensor* selfRef, const aclTensor* end, const aclScalar* weight, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceLerps(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceMaskedFillScalarGetWorkspaceSize(aclTensor* selfRef, const aclTensor* mask, const aclScalar* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceMaskedFillScalar(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceMaskedFillTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* mask, const aclTensor* value, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceMaskedFillTensor(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceMaskedScatterGetWorkspaceSize(aclTensor* selfRef, const aclTensor* mask, const aclTensor* source, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceMaskedScatter(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNanToNumGetWorkspaceSize(const aclTensor* self, float nan, float posinf, float neginf, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNanToNum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceNanToNumGetWorkspaceSize(aclTensor* selfRef, float nan, float posinf, float neginf, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceNanToNum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceOneGetWorkspaceSize(const aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceOne(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPowTensorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* exponent, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPowTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplacePowTensorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* exponent, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplacePowTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPowScalarTensorGetWorkspaceSize(const aclScalar* self, const aclTensor* exponent, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPowScalarTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplacePutGetWorkspaceSize(aclTensor* selfRef, const aclTensor* index, const aclTensor* source, bool accumulate, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplacePut(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRemainderTensorTensorGetWorkspaceSize(const aclTensor* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRemainderTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRemainderTensorScalarGetWorkspaceSize(const aclTensor* self, const aclScalar* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRemainderTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnRemainderScalarTensorGetWorkspaceSize(const aclScalar* self, const aclTensor* other, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnRemainderScalarTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceRemainderTensorTensorGetWorkspaceSize(aclTensor* selfRef, const aclTensor* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRemainderTensorTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceRemainderTensorScalarGetWorkspaceSize(aclTensor* selfRef, const aclScalar* other, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRemainderTensorScalar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceScatterUpdateGetWorkspaceSize(aclTensor* data, const aclTensor* indices, const aclTensor* updates, int64_t axis, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceScatterUpdate(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceZeroGetWorkspaceSize(aclTensor* selfRef, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceZero(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIsInScalarTensorGetWorkspaceSize(const aclScalar* element, const aclTensor* testElements, bool assumeUnique, bool invert, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIsInScalarTensor(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInstanceNormGetWorkspaceSize(const aclTensor* x, const aclTensor* gamma, const aclTensor* beta, const char* dataFormat, double eps, aclTensor* y, aclTensor* mean, aclTensor* variance, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInstanceNorm(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAdaptiveAvgPool2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAdaptiveAvgPool2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnAdaptiveAvgPool3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAdaptiveAvgPool3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnAvgPool2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclIntArray* kernelSize, const aclIntArray* stride, const aclIntArray* padding, bool ceilMode, bool countIncludePad, int64_t divisorOverride, int8_t cubeMathType, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnAvgPool2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBatchNormBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input, const aclTensor* weight, const aclTensor* runningMean, const aclTensor* runningVar, const aclTensor* saveMean, const aclTensor* saveInvstd, bool training, double eps, const aclBoolArray* outputMask, aclTensor* gradInput, aclTensor* gradWeight, aclTensor* gradBias, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBatchNormElemtGetWorkspaceSize(const aclTensor* input, const aclTensor* weight, const aclTensor* bias, aclTensor* mean, aclTensor* invstd, double eps, aclTensor* output, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormElemt(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBatchNormElemtBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input, const aclTensor* mean, const aclTensor* invstd, const aclTensor* weight, const aclTensor* sumDy, const aclTensor* sumDyXmu, aclTensor* counter, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormElemtBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBatchNormGatherStatsWithCountsGetWorkspaceSize( const aclTensor* input, const aclTensor* mean, const aclTensor* invstd, aclTensor* runningMean, aclTensor* runningVar, double momentum, double eps, const aclTensor* counts, aclTensor* meanAll, aclTensor* invstdAll, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormGatherStatsWithCounts(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBatchNormStatsGetWorkspaceSize(const aclTensor* input, double eps, aclTensor* mean, aclTensor* invstd, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormStats(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBinaryCrossEntropyGetWorkspaceSize(const aclTensor* self, const aclTensor* target, const aclTensor* weight, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBinaryCrossEntropy(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnBinaryCrossEntropyBackwardGetWorkspaceSize( const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, const aclTensor* weightOptional, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBinaryCrossEntropyBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBinaryCrossEntropyWithLogitsGetWorkspaceSize( const aclTensor* self, const aclTensor* target, const aclTensor* weightOptional, const aclTensor* posWeightOptional, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBinaryCrossEntropyWithLogits(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnBinaryCrossEntropyWithLogitsBackwardGetWorkspaceSize( const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, const aclTensor* weightOptional, const aclTensor* posWeightOptional, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBinaryCrossEntropyWithLogitsBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnConvolutionBackwardGetWorkspaceSize( const aclTensor* gradOutput, const aclTensor* input, const aclTensor* weight, const aclIntArray* biasSizes, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool transposed, const aclIntArray* outputPadding, int groups, const aclBoolArray* outputMask, int8_t cubeMathType, aclTensor* gradInput, aclTensor* gradWeight, aclTensor* gradBias, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnConvTbcBackwardGetWorkspaceSize(const aclTensor* self, const aclTensor* input, const aclTensor* weight, const aclTensor* bias, int64_t pad, int8_t cubeMathType, aclTensor* gradInput, aclTensor* gradWeight, aclTensor* gradBias, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnConvolutionBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnConvTbcBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnCtcLossGetWorkspaceSize(const aclTensor* logProbs, const aclTensor* targets, const aclIntArray* inputLengths, const aclIntArray* targetlengths, int64_t blank, bool zeroInfinity, aclTensor* negLogLikelihoodOut, aclTensor* logAlphaOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCtcLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnCtcLossBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* logProbs, const aclTensor* targets, const aclIntArray* inputLengths, const aclIntArray* targetLengths, const aclTensor* negLogLikelihood, const aclTensor* logAlpha, int64_t blank, bool zeroInfinity, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnCtcLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDropoutGetWorkspaceSize(const aclTensor* input, double p, bool train, int64_t seed, int64_t offset, aclTensor* out, aclTensor* maskOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDropout(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDropoutBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* mask, double scale, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDropoutBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDropoutDoMaskGetWorkspaceSize(const aclTensor* self, const aclTensor* mask, double prob, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDropoutDoMask(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDropoutGenMaskGetWorkspaceSize(const aclIntArray* shape, double prob, int64_t seed, int64_t offset, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDropoutGenMask(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnDropoutGenMaskV2GetWorkspaceSize(const aclIntArray* shape, double prob, int64_t seed, int64_t offset, aclDataType probDataType, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnDropoutGenMaskV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclScalar* alpha, const aclScalar* scale, const aclScalar* inputScale, bool isResult, const aclTensor* selfOrResult, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnEmbeddingDenseBackwardGetWorkspaceSize(const aclTensor* grad, const aclTensor* indices, uint64_t numWeights, uint64_t paddingIdx, bool scaleGradByFreq, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnEmbeddingDenseBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionScoreGradGetWorkspaceSize( const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy, const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional, const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionScoreGrad(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionUnpaddingScoreGradGetWorkspaceSize( const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy, const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional, const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional, const aclIntArray *actualSeqQLenOptional, const aclIntArray *actualSeqKvLenOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionUnpaddingScoreGrad(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionScoreGradV2GetWorkspaceSize( const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy, const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional, const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional, const aclIntArray *qStartIdxOptional, const aclIntArray *kvStartIdxOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, int64_t pseTypeOptional, const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionScoreGradV2(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnFlashAttentionUnpaddingScoreGradV2GetWorkspaceSize( const aclTensor *query, const aclTensor *keyIn, const aclTensor *value, const aclTensor *dy, const aclTensor *pseShiftOptional, const aclTensor *dropMaskOptional, const aclTensor *paddingMaskOptional, const aclTensor *attenMaskOptional, const aclTensor *softmaxMaxOptional, const aclTensor *softmaxSumOptional, const aclTensor *softmaxInOptional, const aclTensor *attentionInOptional, const aclIntArray *prefixOptional, const aclIntArray *actualSeqQLenOptional, const aclIntArray *actualSeqKvLenOptional, const aclIntArray *qStartIdxOptional, const aclIntArray *kvStartIdxOptional, double scaleValueOptional, double keepProbOptional, int64_t preTokensOptional, int64_t nextTokensOptional, int64_t headNum, char *inputLayout, int64_t innerPreciseOptional, int64_t sparseModeOptional, int64_t pseTypeOptional, const aclTensor *dqOut, const aclTensor *dkOut, const aclTensor *dvOut, const aclTensor *dpseOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnFlashAttentionUnpaddingScoreGradV2(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnGeGluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* gelu, int64_t dim, int64_t approximate, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeGluV3BackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* gelu, int64_t dim, int64_t approximate, bool activateLeft, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeGluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeGluV3Backward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGeluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeluBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGeluV2GetWorkspaceSize(const aclTensor* x, int64_t approximate, aclTensor* y, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeluV2(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGeluBackwardV2GetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, char *approximate, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGeluBackwardV2(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnGluBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* self, int64_t dim, const aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGridSampler2DBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* input, const aclTensor* grid, int64_t interpolationMode, int64_t paddingMode, bool alignCorners, const aclBoolArray* outputMask, aclTensor* inputGrad, aclTensor* gridGrad, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGridSampler2DBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGridSampler3DBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* input, const aclTensor* grid, int64_t interpolationMode, int64_t paddingMode, bool alignCorners, const aclBoolArray* outputMask, aclTensor* inputGrad, aclTensor* gridGrad, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGridSampler3DBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnGroupNormBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input, const aclTensor* mean, const aclTensor* rstd, const aclTensor* gamma, int64_t N, int64_t C, int64_t HxW, int64_t group, const aclBoolArray* outputMask, aclTensor* gradInput, aclTensor* gradGammaOut, aclTensor* gradBetaOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnGroupNormBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnHardshrinkBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclScalar* lambd, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardshrinkBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnHardsigmoidBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardsigmoidBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnHardswishBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardswishBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnHardtanhBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclScalar* min, const aclScalar* max, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnHardtanhBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIm2colBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclIntArray* inputSize, const aclIntArray* kernelSize, const aclIntArray* dilation, const aclIntArray* padding, const aclIntArray* stride, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIm2colBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIsFiniteGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIsFinite(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnIsNegInfGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIsNegInf(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnIsPosInfGetWorkspaceSize(const aclTensor* self, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnIsPosInf(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnKlDivGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction, bool logTarget, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnKlDiv(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnKlDivBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, int64_t reduction, bool logTarget, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnKlDivBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnL1LossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnL1Loss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnL1LossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnL1LossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLayerNormBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* input, const aclIntArray* normalizedShape, const aclTensor* mean, const aclTensor* rstd, const aclTensor* weightOptional, const aclTensor* biasOptional, const aclBoolArray* outputMask, aclTensor* gradInputOut, aclTensor* gradWeightOut, aclTensor* gradBiasOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLayerNormBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLeakyReluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclScalar* negativeSlope, bool selfIsResult, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLeakyReluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogSigmoidBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* buffer, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogSigmoidBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnLogSoftmaxBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output, int64_t dim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnLogSoftmaxBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxPool2dWithMaskBackwardGetWorkspaceSize( const aclTensor* gradOutput, const aclTensor* self, const aclTensor* indices, const aclIntArray* kernelSize, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool ceilMode, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxPool2dWithMaskBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxPool2dWithIndicesBackwardGetWorkspaceSize( const aclTensor* gradOutput, const aclTensor* self, const aclTensor* indices, const aclIntArray* kernelSize, const aclIntArray* stride, const aclIntArray* padding, const aclIntArray* dilation, bool ceilMode, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxPool2dWithIndicesBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxUnpool2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* indices, const aclIntArray* outputSize, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxUnpool2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMaxUnpool3dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* indices, const aclIntArray* outputSize, const aclIntArray* stride, const aclIntArray* padding, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMaxUnpool3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMishBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMishBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMseLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMseLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMseLossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMseLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMseLossOutGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMseLossOut(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnMultilabelMarginLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, aclTensor* isTarget, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnMultilabelMarginLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNLLLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, const aclTensor* weight, int64_t reduction, int64_t ignoreIndex, aclTensor* out, aclTensor* totalWeightOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNLLLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNLLLoss2dGetWorkspaceSize(const aclTensor* self, const aclTensor* target, const aclTensor* weight, int64_t reduction, int64_t ignoreIndex, aclTensor* out, aclTensor* totalWeightOut, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNLLLoss2d(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNLLLoss2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, const aclTensor* weight, int64_t reduction, int64_t ignoreIndex, aclTensor* totalWeight, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNLLLoss2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnNLLLossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, const aclTensor* weight, int64_t reduction, int64_t ignoreIndex, const aclTensor* totalWeight, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnNLLLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPolarGetWorkspaceSize(const aclTensor* input, const aclTensor* angle, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPolar(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPreluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* weight, aclTensor* gradInput, aclTensor* gradWeight, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnPreluBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnPromptFlashAttentionV2GetWorkspaceSize( const aclTensor *query, const aclTensor *key, const aclTensor *value, const aclTensor *pseShift, const aclTensor *attenMask, const aclIntArray *actualSeqLengths, const aclIntArray *actualSeqLengthsKv, const aclTensor *deqScale1, const aclTensor *quantScale1, const aclTensor *deqScale2, const aclTensor *quantScale2, const aclTensor *quantOffset2, int64_t numHeads, double scaleValue, int64_t preTokens, int64_t nextTokens, char *inputLayout, int64_t numKeyValueHeads, int64_t sparseMode, const aclTensor *attentionOut, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnPromptFlashAttentionV2( void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnReduceNansumGetWorkspaceSize(const aclTensor* self, const aclIntArray* dim, bool keepDim, aclDataType dtype, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReduceNansum(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReflectionPad1dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclIntArray* padding, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReflectionPad1dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReplicationPad1dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclIntArray* padding, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReplicationPad1dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSeluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* result, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSeluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSigmoidBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSigmoidBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSiluBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSiluBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnSmoothL1LossBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclTensor* self, const aclTensor* target, int64_t reduction, float beta, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSmoothL1LossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftMarginLossGetWorkspaceSize(const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftMarginLoss(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftMarginLossBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclTensor* target, int64_t reduction, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftMarginLossBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftmaxBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output, int64_t dim, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftmaxBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftplusBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclScalar* beta, const aclScalar* threshold, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftplusBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnSoftshrinkBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclScalar* lambda, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnSoftshrinkBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnTanhBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* output, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnTanhBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnThresholdBackwardGetWorkspaceSize(const aclTensor *gradOutput, const aclTensor *self, const aclScalar *threshold, aclTensor *out, uint64_t *workspaceSize, aclOpExecutor **executor);
aclnnStatus aclnnThresholdBackward(void *workspace, uint64_t workspaceSize, aclOpExecutor *executor, const aclrtStream stream);
aclnnStatus aclnnUpsampleBilinear2dBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleBilinear2dBackwardGetWorkspaceSize( const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, bool alignCorners, double scalesH, double scalesW, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleLinear1dBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleLinear1dBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, bool alignCorners, double scales, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest1dBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, double scales, aclTensor* out, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest1dBackward(void* workspace, uint64_t workspace_size, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleNearest2dBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, double scalesH, double scalesW, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleNearest3dBackwardGetWorkspaceSize( const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, double scalesD, double scalesH, double scalesW, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleNearest3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnUpsampleTrilinear3dBackwardGetWorkspaceSize(const aclTensor* gradOut, const aclIntArray* outputSize, const aclIntArray* inputSize, bool alignCorners, double scalesD, double scalesH, double scalesW, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnUpsampleTrilinear3dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnChamferDistanceBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnChamferDistanceBackwardGetWorkspaceSize(const aclTensor* xyz1, const aclTensor* xyz2, const aclTensor* idx1, const aclTensor* idx2, const aclTensor* gradDist1, const aclTensor* gradDist2, aclTensor* gradXyz1, aclTensor* gradXyz2, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormReduceBackwardGetWorkspaceSize( const aclTensor* gradOut, const aclTensor* input, const aclTensor* mean, const aclTensor* invstd, const aclTensor* weight, const bool inputG, const bool weightG, const bool biasG, aclTensor* sumDy, aclTensor* sumDyXmu, aclTensor* gradWeight, aclTensor* gradBias, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnBatchNormReduceBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnInplaceNormalGetWorkspaceSize(const aclTensor* selfRef, float mean, float std, int64_t seed, int64_t offset, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceNormal(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnInplaceRandomGetWorkspaceSize(const aclTensor* selfRef, int64_t from, int64_t to, int64_t seed, int64_t offset, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnInplaceRandom(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, aclrtStream stream);
aclnnStatus aclnnReflectionPad2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclIntArray* padding, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReflectionPad2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);
aclnnStatus aclnnReplicationPad2dBackwardGetWorkspaceSize(const aclTensor* gradOutput, const aclTensor* self, const aclIntArray* padding, aclTensor* gradInput, uint64_t* workspaceSize, aclOpExecutor** executor);
aclnnStatus aclnnReplicationPad2dBackward(void* workspace, uint64_t workspaceSize, aclOpExecutor* executor, const aclrtStream stream);